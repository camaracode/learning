#### kubernetes ####

# instalação do kind
- instala kubernetes utilizando containers docker, dessa forma não temos a obrigatoriedade de criação de VMs 
https://kind.sigs.k8s.io/

- necessário instalar kubectl
https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-using-native-package-management

- instalando kind (linux)
$ curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.11.1/kind-linux-amd64
$ chmod +x ./kind
$ sudo mv ./kind /usr/local/bin/kind

OBS: 
$ env -> checa nossas variaveis de ambiente
Ótimo post para explicar sobre $PATH:
https://linuxize.com/post/how-to-add-directory-to-path-in-linux/

# principais comandos do kind
- gerando um cluster com apenas um nó 
IMPORTANTE: especificar versão da imagem node
$ kind create cluster --image kindest/node:v1.23.0

- local do arquivo de configuração
$ cat ~/.kube/config

- conectando o kubectl ao cluster 
$ kubectl cluster-info --context kind-kind
OBS: kind-kind é o nome do cluster que poder configurado com o parametro --name na criação do cluster

- para identificar se tá funcionando
$ kubectl get nodes

- obter todos os clusters
$ kind get clusters

- deletar clusters
$ kind delete clusters NOME_CLUSTER

**** gerando um cluster com multi nós
- criar um arquivo yaml para configuração do cluster

kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
    protocol: TCP
- role: worker    
- role: worker
- role: worker

- gerando cluster passando as configurações e um nome
$ kind create cluster --config=k8s/cluster-config.yaml --name=robertocamara --image kindest/node:v1.23.0

- obter nomes dos clusters pelo kubectl
$ kubectl config get-clusters

- mudar contexto de uso do cluster
$ kubectl config use-context NOME_CLUSTER (kubectl config get-clusters)

- instalar extension do [kubernetes] para facilitar o gerenciamento dos clusters

## criando Pods ##
- criar arquivo yaml
- executar arquivo yaml
$ kubectl apply -f pod.yaml

- testar se o pod tá funcionando (redirecionamento de porta)
$ kubectl port-forward pod/webapp 8080:80

- apagar pod
$ kubectl delete pod webapp

## criando replicaset (gerencia os pods)
$ kubectl get replicasets

- deletar ReplicaSet
$ kubectl delete replicaset NOME_REPLICASET

- problemas com replicasets
Caso uma nova versão da aplicação seja gerada, mesmo configurando o novo replicaset, os pods não são atualizados, 
apenas se deletar e recriar o pod.

O kubernetes tem um objeto pra resolver esse problema, que é o Deployment
Hierarquia: 
    Deployment -> ReplicaSet -> Pod

Ao fazer um novo Deployment, o kubernetes recria o ReplicaSet e consequentemente os Pods.
Para realizar esse operação, basta alterar o kind do arquivo yaml para "Deployment".

- obter deployments
$ kubectl get deployments

### Rollout e Revisões ###
- obter lista do histórico do kubernetes
$ kubectl rollout history deployment NOME_DEPLOYMENT

- como voltar pra versão anterior do deployment 
$ kubectl rollout undo deployment NOME_DEPLOYMENT 

- voltar para uma revisão específica
$ kubectl rollout undo deployment NOME_DEPLOYMENT --to-revision=2

- detalhamento do deployment em execução
$ kubectl describe deployment NOME_DEPLOYMENT

#### Services ####
- obter services 
$ kubectl get services ou kubectl get svc 

- criando um redirecionamento para acesso externo
$ kubectl port-forward service/webapp-service 8090:80

IMPORTANTE: 
Caso a porta do container não esteja na 80, precisamos utilizar o "targetPort", 
para que o service saiba redirecionar para a porta do container.
Resumindo: 
    port: é a porta do service
    targetPort: é a porta do container


### Proxy para acessar a API do kubernetes ### 
- criando um proxy 
$ kubectl proxy --port=8080

### Service Type - ClusterIP ###
Gera IP interno para o service 

### Service Type - NodePort ###
Consegue expor o service através de uma porta 
OBS: normalmente não é muito utilizado 

### Service Type - LoadBalancer ###
Gera um ip para acessar externamente


##### Objetos de configuração #####
- variáveis de ambiente
Ex: 
...
 spec:
      containers:
        - name: webapp
          image: robertocamara/webapp-kubernetes:v3
          env:
            - name: MYNAME
              value: "Roberto Camara"

- utilizando variaveis de ambiente com ConfigMap
Ex arquivo configMap
apiVersion: v1
kind: ConfigMap
metadata:
  name: webapp-env
data:
  MYNAME: Roberto Alves Camara 

Ex: 
...
   spec:
      containers:
        - name: webapp
          image: robertocamara/webapp-kubernetes:v3
          envFrom: # dessa forma o kubernetes entende que tem que carregar todas as variaveis
            - configMapRef:
                name: webapp-env
          # outra forma
          # env:
          #   - name: MYNAME
          #     valueFrom:                
          #       configMapKeyRef:
          #         name: webapp-env
          #         key: MYNAME              

- injetando ConfigMap no container (evitar recriar imagens)
EX:
...
    spec:
      containers:
        - name: webapp
          image: robertocamara/webapp-kubernetes:v4
          envFrom: # dessa forma o kubernetes entende que tem que carregar todas as variaveis
            - configMapRef:
                name: webapp-env
          volumeMounts:
            - mountPath: "/app/staticfiles"
              name: config      
      volumes:
        - name: config 
          configMap:
            name: configmap-skills 
            items:
              - key: skills
                path: "skills.txt"


- acessar pod 
$ kubectl exec -it NOME_POD -- bash

- logs pod 
$ kubectl logs NOME_POD

## secrets e variaveis de ambientes ##
IMPORTANTE:
Por padrão, os secrets trabalham com base64.
- Para transformar em base64 no linux.
$ echo "MINHA_STRING" | base64

OBS: ver arquivo secret

### health check ###
- utilizando o livenessProbe para checar a saúde da aplicação
* possui 3 tipos: http, command dentro do container, tcp

- deploy com watch nos pods
$ kubectl apply -f k8s/deployment.yaml && watch -n1 kubectl get pods

- utilizando readiness (verifica quando a aplicação tá pronta pra receber tráfego)

- utilizando o startupProbe
só habilita o readiness e o liveness, após esse objeto garantir que a aplicação tá no ar.
# caso esteja sendo utilizado não tem necessidade do initialDelaySeconds

### Resources e HPA (horizontal pod autoscale) ###
- instalando metrics-server
https://github.com/kubernetes-sigs/metrics-server

Para funcionar corretamente no kind, será necessário um workaround.
- baixar o arquivo de configuração 
$ wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

- para o metrics-server trabalhar de forma insegura
https://github.com/kubernetes-sigs/metrics-server/issues/525

* add nos argumentos do container no Deployment 
- --kubelet-insecure-tls

- executar o metrics-server 
$ kubectl apply -f metrics-server.yaml

- para verificar se está funcionando
$ kubectl get apiservices
* localizar "v1beta1.metrics.k8s.io", se available True.

- configurando os recurso dos containers
EX:
...
spec:
    containers:
    - name: webapp
        image: robertocamara/webapp-kubernetes:v5.2
        resources:
        requests: # configura o mínimo exigido pra esse container(pod) funcionar
            cpu: 100m # 100 milicores
            memory: 20Mi # 20 megas
        limits: # até onde pode utilizar de recurso
            cpu: 500m
            memory: 25Mi

- verificar o consumo de recursos
$ kubectl top pod NOME_POD
$ watch -n1 kubectl top pod NOME_POD

- utilizar HPA (horizontal pod autoscale)
Ex: 
...
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: webapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: webapp
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 30

- para teste de stress
$ kubectl run -it fortio --rm --image=fortio/fortio -- load -qps 800 -t 360s -c 70 "http://webapp-service/WeatherForecast/generate-guid"
$ kubectl run -it fortio --rm --image=fortio/fortio -- load -qps 800 -t 120s -c 70 "http://webapp-service/WeatherForecast/health"
$ kubectl run -it fortio --rm --image=fortio/fortio -- load -qps 2000 -t 360s -c 70 "http://webapp-service/WeatherForecast"  

- observar métricas
$ watch -n1 kubectl get hpa 
$ watch -n1 kubectl get pods 

### StatefulSets e Volumes Persistentes ###
- criando volumes persistentes e montado
$ kubectl get storageclass (diferentes por provider de nuvem)

- get configurações do nosso kind 
$ kubectl config get-contexts

- criando um persistent volume claim (pvc)
ex:
...
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: webapp-pvc
spec:
  resources:
    requests:
      storage: 5Gi
  accessModes:
    - ReadWriteOnce

- consultando os persistents volumes claims (pvc)
$ kubectl get persistentvolumeclaim (ou apenas pvc)

-  montando o bind no deployment
Ex: 
...
      volumeMounts:
            - mountPath: "/app/staticfiles"
              name: config   
            - mountPath: "app/pvc"
              name: webapp-volume # nome que foi definido na criação do volume

      volumes:
        - name: webapp-volume # pode ser qualquer nome
          persistentVolumeClaim:
            claimName: webapp-pvc # aqui deve ser exatamente o nome que foi definido no arquivo de configuração do pvc

* após a configuração do bind, consultar novamente o status do pvc
- $ kubectl get pvc

* para testar o pvc
- acessar um pod ($ kubectl exec -it NOME_POD -- bash)
- criar um arquivo dentro da pasta criada para o volume "/pvc"
- deletar o pod
- quando for recriado, o arquivo deve estar dentro da pasta "/pvc"

# criando StatefulSets
Ex:
...
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  serviceName: mysql-h
  replicas: 2
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: mysql
        env:
          - name: MYSQL_ROOT_PASSWORD
            value: root        
            
- consultar statefulset 
$ kubectl get statefulset

- criando headless service
Ex: 
apiVersion: v1
kind: Service
metadata:
  name: mysql-h # este nome deve ser exatamente o nome que foi definido na tag "serviceName" do arquivo de configuração do statefulset
spec:
  selector: # utilizado para filtrar e selecionar os os apps definidos no mathLabels
    app: mysql 
  ports:
    - port: 3306
  clusterIP: None # service entende que não vai trabalhar com ip e sim com resolução de nome (DNS)

* para testar
- acessar outro pod e ping para outro service, podendo utilizar a resolução de nomes para direcionar a requisição
ex: $ ping mysql-0.mysql-h
    $ ping mysql-1.mysql-h

- criando volumes dinamicamente com statefulset
Ex:
...
    spec:
      containers:
      - name: mysql
        image: mysql
        env:
          - name: MYSQL_ROOT_PASSWORD
            value: root
        volumeMounts:
          - mountPath: /var/lib/mysql
            name: mysql-volume

  volumeClaimTemplates:
  - metadata:
      name: mysql-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi

OBS: analisar arquivo statefulset.yaml

#### ingress ####
Basicamente seria um ponto único de entrada para o kubernetes, faz o roteamento para os services lembrando muito uma api gateway

OBS: tem que testar em algum provider

### cert-manager ####
https://cert-manager.io/docs/

- criando um namespace para o cert-manager
$ kubectl create namespace cert-manager

- https://cert-manager.io/next-docs/installation/kubectl/
$ kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.7.0-alpha.0/cert-manager.yaml

- obter pods pelo namespace do cert-manager 
OBS: -n (namespace)
$ kubectl get po -n cert-manager

- criar cluster issue 
OBS: as features do ingress e cert-manager dependem de um provider de nuvem 

Ex:
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata: 
  name: letsencrypt
  namespace: cert-manager
spec:
  acme: 
    server: https://acme-v02.api.letsencrypt.org/directory
    email: robertocamara@outlook.com.br
    privateKeySecretRef:
      name: letsencrypt-tls
    solvers: 
    - http01:
        ingress:
          class: nginx

- consultar ClusterIssuer          
$ kubectl get ClusterIssuer

#### namespaces ####
OBS: consultar arquivo deployment "k8s/namespaces/deployment.yaml"


- criar namespace 
$ kubectl create namespace dev

- aplicando deploy definindo namespace
$ kubectl apply -f deployment.yaml -n=dev

- consultando deplou namespace específico
$ kubectl get deployments -n=dev

- visualizar configurações do cluster
$ kubectl config view

- context atual 
$ kubectl config current-context

- criando contextos por namespace
$ kubectl config set-context NOME_CONTEXT --namespace=NOME_NAMESPACE --cluster=NOME_CLUSTER --user=USUARIO_CLUSTER

- defindo um contexto 
$ kubectl config use-context kind-robertocamara (my default)
$ kubectl config use-context dev 
$ kubectl config current-context

ex: kubectl get pods -n=dev 

#### Criando service account e roles ####
- obter service accounts
$ kubectl get serviceaccounts

- checar resources 
$ kubectl api-resources

OBS: essa parte de segurança (ServiceAccount, Role and RoleBinding) tem que ser revista

# código fonte das aulas
https://github.com/codeedu/fc2-k8s



































































































